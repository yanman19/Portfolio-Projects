import pandas as pd
import requests
import os
import zipfile
import io

class EIA860Scraper:
    """
    A class to scrape and process EIA-860 data.
    
    The EIA-860 is the Annual Electric Generator Report that collects generator-level 
    specific information about existing and planned generators.
    """
    
    def __init__(self, year=None, save_dir=None, api_key=None):
        """
        Initialize the EIA-860 scraper.
        
        Args:
            year (int, optional): Year to download data for. Defaults to the most recent available.
            save_dir (str, optional): Directory to save downloaded files. Defaults to current directory.
            api_key (str, optional): EIA API key for alternative API access. Not required for basic scraping.
        """
        self.base_url = "https://www.eia.gov/electricity/data/eia860"
        self.year = year
        self.save_dir = save_dir or os.getcwd()
        self.api_key = api_key
        
    def get_available_years(self):
        """
        Get a list of available years for EIA-860 data.
        
        Returns:
            list: List of available years as integers.
        """
        # Scrape the EIA-860 page to find available years
        response = requests.get(self.base_url)
        if response.status_code != 200:
            raise Exception(f"Failed to access {self.base_url}, status code: {response.status_code}")
        
        # This is a simplistic approach - the actual implementation might need to be 
        # adjusted based on the current EIA website structure
        # Look for links to ZIP files which typically contain the year in their name
        import re
        years = set()
        for match in re.finditer(r'href="([^"]*eia860([^"/]*))\.zip"', response.text):
            year_match = re.search(r'(19|20)\d{2}', match.group(1))
            if year_match:
                years.add(int(year_match.group(0)))
        
        return sorted(list(years), reverse=True)
    
    def download_data(self, year=None):
        """
        Download EIA-860 data for the specified year.
        
        Args:
            year (int, optional): Year to download data for. If None, uses self.year or the most recent.
            
        Returns:
            str: Path to the downloaded zip file.
        """
        year_to_use = year or self.year
        
        if not year_to_use:
            # If no year specified, get the most recent
            available_years = self.get_available_years()
            if not available_years:
                raise Exception("Could not determine available years")
            year_to_use = available_years[0]
        
        # Construct the URL for the specified year
        # This URL pattern might need adjustment based on EIA's current structure
        zip_url = f"{self.base_url}/archive/xls/eia860{year_to_use}.zip"
        
        print(f"Downloading EIA-860 data for {year_to_use}...")
        response = requests.get(zip_url)
        
        if response.status_code != 200:
            # Try alternative URL patterns
            alternative_urls = [
                f"{self.base_url}/xls/eia860{year_to_use}.zip",
                f"{self.base_url}/eia860{year_to_use}.zip"
            ]
            
            for alt_url in alternative_urls:
                print(f"Trying alternative URL: {alt_url}")
                response = requests.get(alt_url)
                if response.status_code == 200:
                    break
            
            if response.status_code != 200:
                raise Exception(f"Failed to download data for {year_to_use}, status code: {response.status_code}")
        
        # Save the zip file
        zip_path = os.path.join(self.save_dir, f"eia860_{year_to_use}.zip")
        with open(zip_path, 'wb') as f:
            f.write(response.content)
        
        print(f"Downloaded to {zip_path}")
        return zip_path
    
    def extract_files(self, zip_path=None, extract_all=False):
        """
        Extract files from the downloaded zip.
        
        Args:
            zip_path (str, optional): Path to the zip file. If None, uses the most recently downloaded.
            extract_all (bool): Whether to extract all files or just the main data files.
            
        Returns:
            dict: Dictionary mapping file names to their extracted paths.
        """
        if not zip_path:
            # Find the most recent zip file in the save directory
            zip_files = [f for f in os.listdir(self.save_dir) if f.startswith("eia860_") and f.endswith(".zip")]
            if not zip_files:
                raise Exception("No downloaded zip files found")
            zip_path = os.path.join(self.save_dir, sorted(zip_files)[-1])
        
        print(f"Extracting files from {zip_path}...")
        extract_dir = os.path.splitext(zip_path)[0]
        os.makedirs(extract_dir, exist_ok=True)
        
        extracted_files = {}
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            # Get list of files in the zip
            file_list = zip_ref.namelist()
            
            # Filter for data files (usually Excel files)
            files_to_extract = file_list
            if not extract_all:
                files_to_extract = [f for f in file_list if f.lower().endswith(('.xlsx', '.xls'))]
            
            # Extract the files
            for file in files_to_extract:
                extracted_path = zip_ref.extract(file, extract_dir)
                extracted_files[file] = extracted_path
                print(f"Extracted: {file}")
        
        return extracted_files
    
    def load_generator_data(self, excel_path=None):
        """
        Load generator data from the EIA-860 Excel file.
        
        Args:
            excel_path (str, optional): Path to the Excel file. If None, tries to find it in extracted files.
            
        Returns:
            pandas.DataFrame: DataFrame containing generator data.
        """
        if not excel_path:
            # Try to find the generator data file in the extracted directory
            extract_dir = os.path.join(self.save_dir, f"eia860_{self.year or ''}")
            if not os.path.exists(extract_dir):
                extracted_files = self.extract_files()
                excel_files = [f for f in extracted_files.values() if f.lower().endswith(('.xlsx', '.xls'))]
                if not excel_files:
                    raise Exception("No Excel files found in extracted data")
                
                # Look for the file containing generator data
                for file in excel_files:
                    if "generator" in file.lower():
                        excel_path = file
                        break
                
                if not excel_path:
                    excel_path = excel_files[0]  # Just use the first Excel file if can't identify
        
        print(f"Loading generator data from {excel_path}...")
        
        # The EIA-860 file typically has multiple sheets
        # We'll try to identify and load the generator data
        xl = pd.ExcelFile(excel_path)
        
        # Find sheets that likely contain generator data
        generator_sheets = [s for s in xl.sheet_names if 'generator' in s.lower()]
        
        if not generator_sheets:
            print("Could not find a sheet with 'generator' in the name. Available sheets:")
            for sheet in xl.sheet_names:
                print(f" - {sheet}")
            
            # Try to use "3_1_Generator" or similar naming patterns
            generator_sheets = [s for s in xl.sheet_names if '3_1' in s or 'plant' in s.lower()]
            
            if not generator_sheets:
                # Just use the first sheet if can't identify
                generator_sheets = [xl.sheet_names[0]]
        
        print(f"Loading generator data from sheet: {generator_sheets[0]}")
        
        # Usually, the generator data has headers a few rows down
        try:
            df = pd.read_excel(excel_path, sheet_name=generator_sheets[0], skiprows=1)
        except:
            # If that fails, try different skiprows values
            for skip in range(5):
                try:
                    df = pd.read_excel(excel_path, sheet_name=generator_sheets[0], skiprows=skip)
                    break
                except:
                    continue
        
        # Clean up column names (remove whitespace, etc.)
        df.columns = [str(col).strip() for col in df.columns]
        
        # Drop empty rows
        df = df.dropna(how='all')
        
        # Print data overview
        print(f"Loaded {len(df)} generator records")
        print("Column names:", df.columns.tolist())
        
        return df
    
    def load_all_data(self, extract_dir=None):
        """
        Load all relevant data tables from the EIA-860 files.
        
        Args:
            extract_dir (str, optional): Directory containing extracted files.
            
        Returns:
            dict: Dictionary mapping table names to DataFrames.
        """
        if not extract_dir:
            # Try to find the extracted directory
            extract_dir = os.path.join(self.save_dir, f"eia860_{self.year or ''}")
            if not os.path.exists(extract_dir):
                extracted_files = self.extract_files()
                extract_dir = os.path.dirname(list(extracted_files.values())[0])
        
        # Find all Excel files in the extract directory
        excel_files = []
        for root, _, files in os.walk(extract_dir):
            for file in files:
                if file.lower().endswith(('.xlsx', '.xls')):
                    excel_files.append(os.path.join(root, file))
        
        if not excel_files:
            raise Exception(f"No Excel files found in {extract_dir}")
        
        # Load data from each Excel file
        all_data = {}
        
        for excel_path in excel_files:
            file_name = os.path.basename(excel_path)
            print(f"Processing {file_name}...")
            
            xl = pd.ExcelFile(excel_path)
            
            for sheet_name in xl.sheet_names:
                # Skip sheets that are likely just documentation
                if sheet_name.lower() in ['notes', 'contents', 'readme', 'instructions']:
                    continue
                
                print(f"  Loading sheet: {sheet_name}")
                
                # Try to load the data with different skiprows values
                for skip in range(5):
                    try:
                        df = pd.read_excel(excel_path, sheet_name=sheet_name, skiprows=skip)
                        
                        # Check if this seems like a valid data table
                        if len(df.columns) > 2 and len(df) > 2:
                            # Clean column names
                            df.columns = [str(col).strip() for col in df.columns]
                            
                            # Drop empty rows
                            df = df.dropna(how='all')
                            
                            table_name = f"{os.path.splitext(file_name)[0]}_{sheet_name}"
                            all_data[table_name] = df
                            print(f"    Loaded {len(df)} rows with {len(df.columns)} columns")
                            break
                    except Exception as e:
                        if skip == 4:  # Last attempt
                            print(f"    Failed to load sheet: {e}")
        
        return all_data

def scrape_eia860(year=None, save_dir=None, extract=True, load_data=True):
    """
    Convenience function to scrape EIA-860 data in one step.
    
    Args:
        year (int, optional): Year to download data for.
        save_dir (str, optional): Directory to save downloaded files.
        extract (bool): Whether to extract files from the zip.
        load_data (bool): Whether to load generator data into a DataFrame.
        
    Returns:
        pandas.DataFrame or None: Generator data DataFrame if load_data is True.
    """
    scraper = EIA860Scraper(year=year, save_dir=save_dir)
    
    zip_path = scraper.download_data()
    
    if extract:
        extracted_files = scraper.extract_files(zip_path)
    
    if load_data:
        return scraper.load_generator_data()
    
    return None

# Example usage
if __name__ == "__main__":
    # Get the most recent available year
    scraper = EIA860Scraper()
    available_years = scraper.get_available_years()
    print(f"Available years: {available_years}")
    
    # Scrape the most recent year
    df = scrape_eia860(year=available_years[0] if available_years else None)
    
    # Display the first few rows
    if df is not None:
        print("\nSample data:")
        print(df.head())

"""
USAGE GUIDE
===========

This EIA-860 Scraper provides multiple ways to access and process EIA-860 data:

1. Quick Start:
   ```python
   from eia860_scraper import scrape_eia860
   
   # Get the most recent year's data
   df = scrape_eia860()
   
   # Or specify a year
   df_2022 = scrape_eia860(year=2022)
   ```

2. Step-by-Step Approach:
   ```python
   from eia860_scraper import EIA860Scraper
   
   # Initialize the scraper
   scraper = EIA860Scraper()
   
   # Get available years
   years = scraper.get_available_years()
   print(f"Available years: {years}")
   
   # Download a specific year
   zip_path = scraper.download_data(year=2022)
   
   # Extract files
   extracted_files = scraper.extract_files(zip_path)
   
   # Load generator data
   generator_df = scraper.load_generator_data()
   
   # Or load all tables
   all_data = scraper.load_all_data()
   ```

3. Common Data Analysis Tasks:
   ```python
   # Find all plants in California
   ca_plants = df[df['State'] == 'CA']
   
   # Get total capacity by fuel type
   capacity_by_fuel = df.groupby('Fuel Type (Primary)').agg({
       'Nameplate Capacity (MW)': 'sum'
   }).sort_values('Nameplate Capacity (MW)', ascending=False)
   
   # Find all solar generators
   solar = df[df['Fuel Type (Primary)'].str.contains('Solar', case=False, na=False)]
   ```

Note: The actual column names may vary by year and version of the EIA-860 form.
Make sure to inspect df.columns to see the available fields for your data.
"""