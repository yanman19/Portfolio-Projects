import pandas as pd
import numpy as np
from sklearn.ensemble import GradientBoostingRegressor
from itertools import product
import warnings

warnings.filterwarnings('ignore')

# Load data
data = pd.read_csv('your_data.csv')

# Adjust column names as per your data
# Hour: 'HE'
# Month: 'MONTH'
# Year: 'YEAR'

# Define parameters
train_years = [2021, 2022, 2023]  # Training years
test_year_1 = train_years[-1]     # Last year in training data (2023)
test_year_2 = 2024                # Year to predict (2024)
weather_vars = ['temperature', 'humidity']  # Replace with your actual weather variables
time_vars = ['HE', 'MONTH']
features = weather_vars + time_vars
target = 'load'  # Adjust if your load column has a different name

# Clean data
data = data.dropna(subset=features + [target])

# Ensure data types are correct
data[features] = data[features].apply(pd.to_numeric, errors='coerce')
data[target] = pd.to_numeric(data[target], errors='coerce')

# Function to calculate load growth with adjusted predictions
def calculate_load_growth_with_adjusted_predictions(
    data, train_years, test_year_1, test_year_2, features, target
):
    # Split data
    train_data = data[data['YEAR'].isin(train_years)]
    test_data_1 = data[data['YEAR'] == test_year_1]
    
    # Create placeholder data for test_year_2
    months = range(1, 13)
    hours = range(0, 24)
    month_hour_combinations = list(product(months, hours))
    test_data_2 = pd.DataFrame(month_hour_combinations, columns=['MONTH', 'HE'])
    
    # Merge with average weather conditions
    average_weather = train_data.groupby(['MONTH', 'HE'])[weather_vars].mean().reset_index()
    test_data_2 = pd.merge(test_data_2, average_weather, on=['MONTH', 'HE'], how='left')
    
    # Handle missing weather data
    for var in weather_vars:
        if test_data_2[var].isnull().any():
            test_data_2[var].fillna(train_data[var].mean(), inplace=True)
    
    # Prepare training data
    X_train = train_data[features]
    y_train = train_data[target]
    
    # Prepare test data for test_year_1
    X_test_1 = test_data_1[features]
    y_test_1 = test_data_1[target]
    
    # Prepare test data for test_year_2
    X_test_2 = test_data_2[features]
    
    # Ensure feature consistency
    X_test_2 = X_test_2[X_train.columns]
    
    # Ensure all features are numeric
    X_train = X_train.apply(pd.to_numeric, errors='coerce')
    X_test_1 = X_test_1.apply(pd.to_numeric, errors='coerce')
    X_test_2 = X_test_2.apply(pd.to_numeric, errors='coerce')
    
    # Handle any remaining missing values
    X_train.fillna(X_train.mean(), inplace=True)
    X_test_1.fillna(X_train.mean(), inplace=True)
    X_test_2.fillna(X_train.mean(), inplace=True)
    
    # Train model
    model = GradientBoostingRegressor(
        n_estimators=100,
        max_depth=5,
        learning_rate=0.1,
        random_state=42
    )
    model.fit(X_train, y_train)
    
    # Predict for test_year_1
    y_pred_test_1 = model.predict(X_test_1)
    test_data_1['predicted_load'] = y_pred_test_1
    
    # Calculate residuals (errors) for test_year_1
    test_data_1['residuals'] = test_data_1[target] - test_data_1['predicted_load']
    
    # Calculate average residuals by 'MONTH' and 'HE'
    avg_residuals = test_data_1.groupby(['MONTH', 'HE'])['residuals'].mean().reset_index()
    
    # Predict for test_year_2
    y_pred_test_2 = model.predict(X_test_2)
    test_data_2['predicted_load'] = y_pred_test_2
    
    # Adjust test_year_2 predictions using residuals from test_year_1
    test_data_2 = pd.merge(test_data_2, avg_residuals, on=['MONTH', 'HE'], how='left')
    
    # Fill missing residuals with zero
    test_data_2['residuals'].fillna(0, inplace=True)
    
    # Adjust predictions
    test_data_2['adjusted_prediction'] = test_data_2['predicted_load'] + test_data_2['residuals']
    
    # Calculate load growth for each 'MONTH' and 'HE'
    # Get actual load for test_year_1
    actual_load_test_year_1 = test_data_1.groupby(['MONTH', 'HE'])[target].mean().reset_index()
    actual_load_test_year_1.rename(columns={target: 'actual_load_test_year_1'}, inplace=True)
    
    # Get adjusted prediction for test_year_2
    adjusted_prediction_test_year_2 = test_data_2[['MONTH', 'HE', 'adjusted_prediction']]
    
    # Merge the two datasets
    comparison_df = pd.merge(adjusted_prediction_test_year_2, actual_load_test_year_1, on=['MONTH', 'HE'], how='left')
    
    # Calculate load growth
    comparison_df['load_growth_absolute'] = comparison_df['adjusted_prediction'] - comparison_df['actual_load_test_year_1']
    comparison_df['load_growth_percentage'] = (comparison_df['load_growth_absolute'] / comparison_df['actual_load_test_year_1']) * 100
    
    # Round results
    comparison_df['load_growth_absolute'] = comparison_df['load_growth_absolute'].round(2)
    comparison_df['load_growth_percentage'] = comparison_df['load_growth_percentage'].round(2)
    
    # Keep only relevant columns
    result_df = comparison_df[['MONTH', 'HE', 'load_growth_absolute', 'load_growth_percentage']]
    
    return result_df

# Call the function
results_df = calculate_load_growth_with_adjusted_predictions(
    data, train_years, test_year_1, test_year_2, features, target
)

# Display the results
print("Load Growth for each MONTH and HE:")
print(results_df)
