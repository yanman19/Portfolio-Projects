import pandas as pd
import numpy as np
from sklearn.ensemble import GradientBoostingRegressor
import warnings

# Suppress warnings for cleaner output
warnings.filterwarnings('ignore')

# Load data
data = pd.read_csv('your_data.csv', parse_dates=['timestamp'])

# Ensure 'hour', 'month', and 'year' columns exist
data['hour'] = data['timestamp'].dt.hour
data['month'] = data['timestamp'].dt.month
data['year'] = data['timestamp'].dt.year

# Define parameters
month = 7  # July
train_years = [2022]  # Years to train on
test_years = [2023]   # Years to test on
weather_vars = ['temperature', 'humidity']  # Replace with your actual weather variables
target = 'load'  # The load column in your dataset

# Define the function to calculate weather-normalized load growth using GradientBoostingRegressor
def calculate_weather_normalized_load_growth_gbr(
    data, month, train_years, test_years, weather_vars, target
):
    results_list = []

    for hour in range(24):
        # Filter data for the specified hour and month
        filtered_data = data[
            (data['hour'] == hour) &
            (data['month'] == month)
        ]
        
        # Separate data into training and testing sets based on specified years
        train_data = filtered_data[filtered_data['year'].isin(train_years)]
        test_data = filtered_data[filtered_data['year'].isin(test_years)]
        
        # Check if data for training and testing years is available
        if train_data.empty or test_data.empty:
            print(f"No data available for hour {hour}.")
            continue  # Skip this hour if data is missing
        
        # Prepare features and target for training
        X_train = train_data[weather_vars]
        y_train = train_data[target]
        
        # Prepare features and target for testing
        X_test = test_data[weather_vars]
        y_test = test_data[target]
        
        # Initialize and train the GradientBoostingRegressor model
        model = GradientBoostingRegressor(
            n_estimators=100,
            max_depth=5,
            learning_rate=0.1,
            random_state=42
        )
        model.fit(X_train, y_train)
        
        # Predict load for test data
        y_pred_test = model.predict(X_test)
        
        # Calculate residuals (errors)
        residuals = y_test.values - y_pred_test
        
        # Calculate average load growth
        average_load_growth = np.mean(residuals)
        
        # Calculate percentage load growth relative to average load in training data
        average_load_train = np.mean(y_train)
        percentage_load_growth = (average_load_growth / average_load_train) * 100
        
        # Round the results to two decimal places
        average_load_growth = round(average_load_growth, 2)
        percentage_load_growth = round(percentage_load_growth, 2)
        
        # Append results to the list
        results_list.append({
            'hour': hour,
            'average_load_growth': average_load_growth,
            'percentage_load_growth': percentage_load_growth
        })
    
    # Create a DataFrame from the results
    results_df = pd.DataFrame(results_list)
    
    return results_df

# Call the function and save the results to a variable
results_df = calculate_weather_normalized_load_growth_gbr(
    data, month, train_years, test_years, weather_vars, target
)

# Display the results DataFrame
print("Weather-normalized load growth for each hour:")
print(results_df)
